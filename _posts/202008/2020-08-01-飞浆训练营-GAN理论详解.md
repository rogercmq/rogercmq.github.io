---
layout: post
title: 公开课笔记 -- PaddlePaddle顶会论文复现营 GAN理论详解
categories: [CourseNotes, GAN]
description: 
keywords: 
---

百度顶会复现营 Day 2: GAN概述，原理与改进，应用场景 (20200730)

![](/images/PaddlePaddle/GAN/0.png)

# GAN 概述 

GAN的核心思想: 通过生成网络 Generator 和判别网络 Discriminator 不断博弈，来达到生成类真数据的目的。

![](/images/PaddlePaddle/GAN/1.png)

![](/images/PaddlePaddle/GAN/2.png)

![](/images/PaddlePaddle/GAN/3.png)

![](/images/PaddlePaddle/GAN/4.png)

![](/images/PaddlePaddle/GAN/5.png)

## GAN 目标函数的推导

>  (参考文献: [网友的英文笔记]( http://srome.github.io//An-Annotated-Proof-of-Generative-Adversarial-Networks-with-Implementation-Notes/ ))

![](/images/PaddlePaddle/GAN/GAN_Object_Function_1.png)

![](/images/PaddlePaddle/GAN/GAN_Object_Function_2.png)

## GAN 迭代训练方法: 梯度上升D，梯度下降G

![](/images/PaddlePaddle/GAN/6.png)

![](/images/PaddlePaddle/GAN/7.png)

![](/images/PaddlePaddle/GAN/8.png)

![](/images/PaddlePaddle/GAN/9.png)

## GAN 的优势

![](/images/PaddlePaddle/GAN/10.png)

### VAE 和 GAN 的区别

> 参考：[Jindong Wang's Zhihu]( https://www.zhihu.com/question/317623081 )

VAE和GAN都是生成模型，就是说从训练数据来建模真实的数据分布，然后反过来再用学到的这个模型和分布去生成、建模新的数据。

相同点：

- 生成数据的模式都是用了随机噪声（如常用的就是高斯分布）。 
- 在建模分布时，都需要度量噪声和训练数据的分布差异

**本质的不同点：两个方法的分布度量准则不同（即loss不同）。** 

VAE采用了一种较为显式的度量方法，假定训练数据由另一个分布生成，直接去度量训练数据和噪声的KL散度。由此之上发展出了ELBO理论、reparametration trick等等。 

GAN则巧妙地避开了直接度量分布差异这种方式，而是让神经网络自己通过对抗的方式来学习这个距离。当判别器无法区分这两个分布时，就认为两个分布一致了。 所以本质区别是loss的计算方式不同。

鉴于两种分布度量的准则都不是完美的度量（并且并不存在完美的度量，大家都只能是逼近），所以各有各有问题。**比如VAE生成的图像不够真实，GAN的训练中又会碰到例如mode collapse问题等等**。

## GAN 存在的问题

